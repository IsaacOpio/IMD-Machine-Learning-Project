{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No red flags detected on: https://daliteresearch.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Function to check for red flags on a website\n",
    "def check_website(url):\n",
    "    req_check = requests.get(url)\n",
    "    malicious_words = ['malicious', 'phishing', 'scam', 'fraudulent']\n",
    "    \n",
    "    for word in malicious_words:\n",
    "        if word in req_check.text:\n",
    "            print(f'Red flags detected on: {url}')\n",
    "            return True\n",
    "    \n",
    "    print(f'No red flags detected on: {url}')\n",
    "    return False\n",
    "\n",
    "# Insert the website link here\n",
    "website_url = \"https://daliteresearch.com/\"\n",
    "\n",
    "# Check the website for red flags\n",
    "check_website(website_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Limited contact information detected!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def check_suspicious_url(url):\n",
    "    # Check for misspelled URLs, unusual domain extensions, or extra characters\n",
    "    suspicious_patterns = [r'\\d{3,}', r'\\.com\\.co$', r'\\.php$']\n",
    "    for pattern in suspicious_patterns:\n",
    "        if re.search(pattern, url):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_poor_design_and_content(html_content):\n",
    "    # Check for poor design, grammatical errors, or outdated information\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text_content = soup.get_text()\n",
    "\n",
    "    # Check for common scam-related words\n",
    "    scam_keywords = ['scam', 'phishing', 'fraudulent', 'malware', 'identity theft', 'virus infection',\n",
    "                     'fake security alert', 'malware download', 'scareware', 'sweepstakes scam']\n",
    "\n",
    "    for keyword in scam_keywords:\n",
    "        if keyword in text_content:\n",
    "            return True\n",
    "\n",
    "    # Check for quick money-related words\n",
    "    quick_money_keywords = ['easy money', 'get rich quick', 'instant wealth', 'guaranteed returns',\n",
    "                            'no risk investment', 'financial information disclosure', 'large prizes giveaway',\n",
    "                            'false fee payment']\n",
    "\n",
    "    for keyword in quick_money_keywords:\n",
    "        if keyword in text_content:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def check_unsecured_connection(url):\n",
    "    # Check for unsecured connections (lack of HTTPS)\n",
    "    if not url.startswith('https://'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_limited_contact_information(html_content):\n",
    "    # Check for limited contact information or only an email address\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    contact_info = soup.find_all(['address', 'phone', 'email', 'contact'])\n",
    "\n",
    "    if not contact_info:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def check_website(url):\n",
    "    try:\n",
    "        # Fetch website content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        html_content = response.text\n",
    "\n",
    "        # Check for suspicious URL\n",
    "        if check_suspicious_url(url):\n",
    "            print(\"Warning: Suspicious URL detected!\")\n",
    "\n",
    "        # Check for poor design and content\n",
    "        if check_poor_design_and_content(html_content):\n",
    "            print(\"Warning: Poor design or suspicious content detected!\")\n",
    "\n",
    "        # Check for unsecured connection\n",
    "        if check_unsecured_connection(url):\n",
    "            print(\"Warning: Unsecured connection detected!\")\n",
    "\n",
    "        # Check for limited contact information\n",
    "        if check_limited_contact_information(html_content):\n",
    "            print(\"Warning: Limited contact information detected!\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the website content: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    website_url = input(\"Enter the website URL to check: \")\n",
    "    check_website(website_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positives:\n",
      "- Limited contact information detected\n",
      "\n",
      "Negatives:\n",
      "- No suspicious URL detected\n",
      "- No poor design or suspicious content detected\n",
      "- No unsecured connection detected\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def check_suspicious_url(url):\n",
    "    # Check for misspelled URLs, unusual domain extensions, or extra characters\n",
    "    suspicious_patterns = [r'\\d{3,}', r'\\.com\\.co$', r'\\.php$']\n",
    "    for pattern in suspicious_patterns:\n",
    "        if re.search(pattern, url):\n",
    "            return \"Suspicious URL detected\"\n",
    "    return None\n",
    "\n",
    "def check_poor_design_and_content(html_content):\n",
    "    # Check for poor design, grammatical errors, or outdated information\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text_content = soup.get_text()\n",
    "\n",
    "    # Check for common scam-related words\n",
    "    scam_keywords = ['scam', 'phishing', 'fraudulent', 'malware', 'identity theft', 'virus infection',\n",
    "                     'fake security alert', 'malware download', 'scareware', 'sweepstakes scam']\n",
    "\n",
    "    for keyword in scam_keywords:\n",
    "        if keyword in text_content:\n",
    "            return \"Poor design or suspicious content detected\"\n",
    "\n",
    "    # Check for quick money-related words\n",
    "    quick_money_keywords = ['easy money', 'get rich quick', 'instant wealth', 'guaranteed returns',\n",
    "                            'no risk investment', 'financial information disclosure', 'large prizes giveaway',\n",
    "                            'false fee payment']\n",
    "\n",
    "    for keyword in quick_money_keywords:\n",
    "        if keyword in text_content:\n",
    "            return \"Poor design or suspicious content detected\"\n",
    "\n",
    "    return None\n",
    "\n",
    "def check_unsecured_connection(url):\n",
    "    # Check for unsecured connections (lack of HTTPS)\n",
    "    if not url.startswith('https://'):\n",
    "        return \"Unsecured connection detected\"\n",
    "    return None\n",
    "\n",
    "def check_limited_contact_information(html_content):\n",
    "    # Check for limited contact information or only an email address\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    contact_info = soup.find_all(['address', 'phone', 'email', 'contact'])\n",
    "\n",
    "    if not contact_info:\n",
    "        return \"Limited contact information detected\"\n",
    "\n",
    "    return None\n",
    "\n",
    "def check_website(url):\n",
    "    positives = []\n",
    "    negatives = []\n",
    "\n",
    "    try:\n",
    "        # Fetch website content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        html_content = response.text\n",
    "\n",
    "        # Check for suspicious URL\n",
    "        result = check_suspicious_url(url)\n",
    "        if result:\n",
    "            positives.append(result)\n",
    "        else:\n",
    "            negatives.append(\"No suspicious URL detected\")\n",
    "\n",
    "        # Check for poor design and content\n",
    "        result = check_poor_design_and_content(html_content)\n",
    "        if result:\n",
    "            positives.append(result)\n",
    "        else:\n",
    "            negatives.append(\"No poor design or suspicious content detected\")\n",
    "\n",
    "        # Check for unsecured connection\n",
    "        result = check_unsecured_connection(url)\n",
    "        if result:\n",
    "            positives.append(result)\n",
    "        else:\n",
    "            negatives.append(\"No unsecured connection detected\")\n",
    "\n",
    "        # Check for limited contact information\n",
    "        result = check_limited_contact_information(html_content)\n",
    "        if result:\n",
    "            positives.append(result)\n",
    "        else:\n",
    "            negatives.append(\"Adequate contact information detected\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        negatives.append(f\"Error fetching the website content: {e}\")\n",
    "\n",
    "    return positives, negatives\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    website_url = input(\"Enter the website URL to check: \")\n",
    "    positives, negatives = check_website(website_url)\n",
    "\n",
    "    print(\"\\nPositives:\")\n",
    "    for positive in positives:\n",
    "        print(f\"- {positive}\")\n",
    "\n",
    "    print(\"\\nNegatives:\")\n",
    "    for negative in negatives:\n",
    "        print(f\"- {negative}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
